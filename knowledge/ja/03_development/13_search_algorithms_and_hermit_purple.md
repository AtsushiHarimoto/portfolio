# 13. アルゴリズム & データパイプラインガイド (Algorithms & Data Pipelines Field Guide)

> **種類**: アルゴリズム思考と実務探索 (Algorithmic thinking and practical exploration)  
> **重点**: 基礎的な探索とソートのアルゴリズムを解説し、Moyin のクローラー `ハーミットパープル (Hermit Purple)` が使うファネルパイプラインを分析します。

---

## 序章: アルゴリズムとは何か
非コンピュータサイエンス系から転職した Vibecoding 開発者にとって、「アルゴリズム (Algorithm)」は難解な言葉に聞こえるかもしれません。実際には、特定の問題を解くために明確な入力と出力をもつ有限のステップ群です。AI 補助開発ではこうした手順がライブラリに隠れがちですが、用語を理解すればシステム全体を俯瞰でき、提示するプロンプトも精度を増します。

---

## 1. 探索アルゴリズム (Search Algorithms)：情報の海で目的地を定める
データが百万件を超えるとき、目的の要素を見つけるロジックの効率が性能の主因になります。

### 線形探索 (Linear Search) - 暴力的なベースライン
- **動作**：最初の要素から順番に比較し、最後までたどり着くまで進みます。
- **比喩**：索引がない辞書を最初のページからめくって単語を探すようなものです。
- **評価**：最悪ケースで時間計算量 O(N) なので、データ量が膨らむと自己破壊的です。

### 二分探索 (Binary Search) - 半分折りたたむ刃
- **前提**：対象配列はすでに整列 (Sorted) されている必要があります。
- **動作**：中央値と比較し、ターゲットがある側だけを残して上下を再帰的に切断します。
- **比喩**：「究極の暗証番号 (1～100)」ゲームのように、最初に 50 を当てて右か左に狭めていきます。
- **評価**：O(log N) の高速収束で、B-Tree のような構造の基礎です。

---

## 2. ソートアルゴリズム (Sorting Algorithms)：データを秩序ある隊列へ再構築
整列された配列なしでは二分探索は使えません。混沌を昇順に整えるのがソートです。

### バブルソート (Bubble Sort) - 教科書的だが非効率
- **動作**：隣接する要素同士を比較し、左が右より大きければ交換します。極値がバブルのように末尾へ浮かび上がります。
- **評価**：O(N²) なので古典的な学習用に残すだけで、実務ではほぼ使いません。

### クイックソート (Quick Sort) - 現代的な実務王者
- **動作**：分割統治 (Divide and Conquer) を使い、ピボットを選出して小さい値と大きい値に分け、左右を再帰的に処理します。
- **評価**：平均 O(N log N) を実現し、Python や JavaScript の `sort()`（あるいはその派生である Timsort）のコアに使われています。

---

## 3. ファネルパイプライン (Funnel Pipeline) と情報の精錬
「ファネルアルゴリズム」は理論ではなく、実用的なデータ処理パイプラインです。漏斗の形に似て、上部が原始的なデータを集め、階層ごとのフィルターで雑音を削ぎ落とし、最終的に高純度の信号だけを落とします。

- **流れ**：各ステージは特化したフィルターで重複や不正な入力を除去します。
- **比喩**：川で砂金を洗う作業。最初はたくさん集め、徐々に不要物を洗い流して金だけを残します。

Moyin にはこの思考を体現した CLI マクロ、`ハーミットパープル (Hermit Purple)` があります。

---

## 4. ハーミットパープルの漏斗トポロジー
`ハーミットパープル (Hermit Purple)` は『ジョジョの奇妙な冒険』の遠隔情報を書くスタンドに由来する CLI クロールツールです。GitHub や Reddit のトレンドを徹底的に収集し、AI の知見を生成します。

```mermaid
graph TD
    A[広域スクレイピング層 (Wide-area scraping layer)<br/>GitHub / Reddit] -->|1万件超の未整備ストリーム| B(デ重複層 (Deduplication layer)<br/>正規化とハッシュ除去)
    B -->|価値あり候補数百件| C{LLM 再ランク層 (LLM reranking layer)<br/>Gemini / Grok インサイト}
    C -->|タグ付けされたトレンド| D[報告決定層 (Decision report layer)<br/>Adopt / Hold / Drop]
    D --> E((Markdown まとめ報告))

    style C fill:#D1C4E9,stroke:#512DA8,stroke-width:2px;
```

`fetch-ai-info` を起動すると:

1. **スクレイピング層 (Scraping layer)**：各種オープンソースのトレンドから JSON や HTML を無差別に取得します。
2. **フィルタ層 (Filter layer)**：既出のハッシュと照合して重複や閾値未満のエントリを除外します。
3. **AI 裁定層 (Curate layer)**：生き残った候補を `I1 Gateway` を経由して Gemini / Grok に送り、次の三段階を求めます。
   - **Adopt (採用)**：即座にスプリント化できる価値や構造的突破口。
   - **Hold (観察)**：コミュニティの声量が不足し、スター数を継続監視。
   - **Drop (破棄)**：商用力のないおもちゃライブラリ。
4. **報告層 (Report layer)**：Adopt に分類された情報だけを抽出し、Markdown 形式で短い戦況報告に組み直します。

### ベテラン Vibecoder 向けプロンプト
「Python 製クローラーを作ってください。`ハーミットパープル (Hermit Purple)` の漏斗構造に従い、ステージ 1 で幅広く収集、ステージ 2 で正規表現フィルター、ステージ 3 で LLM を接続した RAG 的要約を行い、各ステージはログ収集と追跡を必須としてください。」

このように構造化すると、AI が低結合で拡張性の高い工業級クロールを返してくれます。
