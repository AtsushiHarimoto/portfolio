# 42. CRUD 覇権の打倒：CQRS とイベントソーシング (Event Sourcing)

> **種類**: マイクロサービス・トップレベルデザインパターン
> **重点**: データベースの「読み取り (Read)」と「書き込み (Write)」の衝突がシステムのパフォーマンスを低下させていることに気づいた時、このアーキテクチャがあなたのデータベースに対する認識を根本から覆します。本章では、古き良き CRUD を捨て去り、金融レベルの銀行や大規模 ERP システムでさえも使用している究極のアーキテクチャ：**CQRS と「イベントソーシング」**の世界へとご案内します。

---

## 序：なぜ CRUD は死へと向かうのか？

私たちはプログラミングを学び始めたその日から、**CRUD (Create, Read, Update, Delete)** を教え込まれてきました。
「Moyin のウォレット残高」を更新したい時は、次のような SQL を発行するだけです：
`UPDATE wallets SET balance = balance - 100 WHERE user_id = 1;`

トラフィックが少ない時は、これは非常に素晴らしいものです。しかし、高並行処理のマイクロサービスクラスターにおいては、**致命的なペインポイント (痛点)** となります：

1. **読み書きの衝突 (Lock Contention / ロック競合)**：ボスが「今月の千万の売上を算出する超複雑な JOIN レポート (読み取り)」を抽出している時、データベースはロックされます。これにより、外で買い物をしているユーザーは「支払いの書き込み」を行うために列に並ぶことを強制され、画面は狂ったようにくるくると回り続けます。
2. **歴史の真実の喪失 (Loss of Intent)**：残高が `$500` になった時、あなたは何が起こったのか全く分かりません！ 手数料が引かれたのか？ システムのバグなのか？ それとも彼が何かを買ったのか？ **なぜなら `UPDATE` 操作は「上書き (Overwrite)」を行い、歴史という名の犯行現場を抹殺してしまうからです。**

---

## 1. 別々の道を歩む：CQRS (コマンドクエリ責務分離)

「読み取り」と「書き込み」のパフォーマンス衝突を解決するため、大手企業のアーキテクトたちは **CQRS (Command Query Responsibility Segregation)** を提唱しました。
この思想は極めて極端です：**「読み取り」と「書き込み」は強制的に分業させなければならず、さらにはデータベースさえも切り離さなければならない！**

### ✍️ コマンド側 (Command) —— 「書き込み」を担当

- 状態を変更する操作 (支払い、記事の投稿など) のみを専門に処理します。
- バックエンドには、MySQL のような トランザクションの ACID 安全性を極めて重視する**リレーショナルデータベース**を使用します。
- ここでは「読み取り」のパフォーマンスなどは気にしません。書き込み時の衝突防止と絶対的な正確性さえ保証できればよいのです。

### 👁️ クエリ側 (Query) —— 「読み取り」を担当

- 画面上の表示 (残高の確認、すべての記事のリストアップなど) のみを専門に処理します。
- バックエンドは Elasticsearch や Redis などの **NoSQL データベース**に変更されます。これらのデータベースの構造は、意図的に「フロントエンド画面のためにオーダーメイドされた」View (ビュー) として設計されており、フロントエンドは JOIN することもなく、取得して直接印字するだけでよく、圧倒的な速度を誇ります！

**ここで問題が起きます：この両者のデータベースはどうやって同期を保つのでしょうか？**
答えは **Kafka や RabbitMQ** を通じ、**非同期イベント (Event Driven)** を利用して Command 側で書き込まれた結果を Query 側のデータベースへと投げ渡すのです。

---

## 2. 帳簿だけで残高カラムが存在しない：イベントソーシング (Event Sourcing)

CQRS の効果を極限まで引き出すために、アーキテクトは MySQL の中にある `balance` カラムそのものを直接削除してしまいます！

### 📜 すべての変更は一つの「イベント」である

Event Sourcing 架構において、システムは**決して「現在の状態」を保存しません。システムは「発生したイベントのストリーム (流れ)」のみを保存します**。
データベース (EventStore DB や Kafka など) の最初から最後まで、この一つの長い配列が存在するだけです (極速の Append-only 書き込みであり、ロックの問題はありません)：

1. 【イベント】`UserCreated` (Moyin が参加した)
2. 【イベント】`MoneyDeposited` (1000 ドル入金された)
3. 【イベント】`ItemPurchased` (剣を買って 200 ドル引かれた)
4. 【イベント】`ItemPurchased` (盾を買って 300 ドル引かれた)

### 🧮 犯行現場の再現 (Replay / リプレイ)

- **もし残高を調べたい時はどうする？**
  その人の人生の始まりから現在に至るまでのすべてのイベントを最初から「リプレイ (Replay) して足し引き」すれば、残高が 500 ドルであると導き出せます。
- **もしバグを調査したい時はどうする？**
  完璧です！ `UPDATE` でデータを上書きしたことが一度もないため、ハッカーの改ざんであろうがシステムエラーであろうが、すべてイベントストリームの中で恥辱の柱に死に物狂いで釘付けにされているからです。
- **「年間消費円グラフ」という機能を新しく追加したい時はどうする？**
  従来のアーキテクチャなら、今日から少しずつ記録を集め始めなければなりません。イベントソーシングにおいては、古いイベントの配列を「天地開闢の時からもう一度リプレイして、新しい MongoDB の円グラフコレクションに流し込む」だけで、昨日リリースされた新機能が、今日には過去 10 年分のグラフデータを備えていることになるのです！

---

## 💡 Vibecoding 指令

AI に金融取引や厳格な監査制度を伴うコアエンジンをリファクタリングさせる際：

> 🗣️ `「この【口座資金の総勘定元帳マイクロサービス】を設計する際、私に UPDATE するような Entity モデルを書くことは直ちにやめてください！ これは財務システムへの冒涜です。私はあなたに【CQRS と Event Sourcing (イベントソーシング)】のデザインパターンを適用することを要求します。書き込み側 (Command) は、出金などのアクションを Immutable (変更不可能) なイベントストリームへと変換し、それを Kafka に Append 書き込みしなければなりません。そして独立した Worker がそれらのイベントをリッスンし、フロントエンドの画面に高速なクエリ (Query) 結果を提供するための、MySQL 側のビューテーブル (Read Model) をリアルタイムで更新 (Project) させてください！」`
