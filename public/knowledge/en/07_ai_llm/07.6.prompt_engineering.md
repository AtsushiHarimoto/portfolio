# 07.6. Prompt Engineering: Core Principles for Commanding AI

> **Type**: Development Guidelines and AI Behavior Control
> **Focus**: How to construct precise System Prompts within application logic, forcing large language models to produce stable, structured output with built-in self-correction resilience.

---

## Preface: AI as an Improv Actor

Within the Moyin engine architecture, the Large Language Model (LLM) plays the role of a soul-driving core component. However, its nature closely resembles an unconstrained "improv actor" -- without strict script specifications and directorial commands, its output will rapidly diverge and drift from the system's intended trajectory.

This guide teaches how to exert absolute engineering control and behavioral convergence on the LLM through carefully crafted "Prompts."

---

## 1. Dual-Track Prompting Architecture

Within the API communication protocol, we explicitly define two dimensions of message hierarchy:

### System Prompt (Global System Instructions)

- **Role**: "The director's invisible megaphone." This layer carries extremely high weight and is exclusive to the system backend, beyond the reach of end users.
- **Responsibilities**:
  1. Anchor the global world-building and NPC personality attributes (e.g., "Your name is Lin Wan; you are aloof yet perceptive...").
  2. **Engineering boundary constraints**: Mandate the return format to ensure system parsing never breaks.

### User Prompt (Environment and Player Input)

- **Role**: "Real-time dialogue and scene changes happening on stage."
- **Responsibilities**: Convey the rapidly shifting interactive state. Examples: "[Player] chooses to hand over the umbrella," or encapsulated environment parameters: "[System Event] Evening falls; the bell chimes."

---

## 2. Output Structuring: Ensuring Stable API Throughput (Enforcing JSON Format)

Large language models have an innate compulsion for verbose preamble. For a program backend, any extraneous opening remark (e.g., "Sure, here's the plot for you:") will trigger a fatal `JSON Parse Error` exception.

### A. Concrete Template Mapping (One-Shot Example)

- **Tactic**: Never rely on verbal constraints alone. Directly inscribe a perfect JSON output example at the bottom of the System Prompt.
- **Template phrasing**: "Output strictly and exclusively a JSON string conforming to the structure below. **Absolutely no** Markdown tags, preamble, or thinking process may be included:"

### B. Hidden Chain of Thought

To allow the AI to perform deep causal reasoning (such as determining whether a player action warrants a relationship score deduction) without contaminating the final output's purity:

- **Solution**: Enable models with deep-thinking mechanisms (e.g., Grok-thinking or DeepSeek-R1), but in the backend's Response Interceptor, use regex to forcibly strip all `<thought>...</thought>` blocks, extracting only the final JSON payload for routing.

### C. Robustness and Self-Healing Mechanism

Models still have a probability of missing closing braces `}` or omitting fields.

- **Architectural safeguard**: Deploy a `try-catch` replay mechanism on the server side. When a parse exception is caught, the gateway does not discard the response outright. Instead, it packages the error string (including the stack trace) back into the User Prompt and resubmits to the AI: "Your previous response was flagged for JSON structural corruption at line 4. Please repair and resend immediately." In practice, most high-tier models self-heal perfectly on the retry.

---

## 3. Guarding Against Common Format-Collapse Landmines

When interfacing with programming languages, watch out for the following symbol contamination hazards:

- **No Markdown character pollution**: Some models have a strong habitual tendency to wrap strings with \`\`\`json as prefix and suffix. The Prompt must repeatedly forbid this behavior, or an intermediate layer must enforce `string.replace` sanitization.
- **Double-Quote Hell**: Since JSON keys and values are wrapped in English double quotes `"`, if the story dialogue also uses English double quotes, it will directly truncate the syntax tree.
  - **Mandatory countermeasure**: Hard-code in the System Prompt: "Within narration and dialogue fields, you must use only CJK quotation marks to delimit speech. Mixing in English quotation marks is strictly forbidden."

---

## 4. Using the Sandbox Testing Tool (Vibe Tester)

Never modify source code and restart the server without any sandbox rehearsal. The Moyin backend is equipped with a dedicated **frontend sandbox testing interface (Tester)**. Follow this testing loop:

1. Open the development test endpoint (default path is typically a sub-page of `http://localhost:5173`).
2. Use the dropdown menu to switch to the specific model inference provider (Provider API) you wish to verify.
3. Place the drafted System Prompt into the console panel and simulate various types of adversarial player input.
4. After submitting, directly inspect the format purity in the `Response RAW Data` panel.

Only after 5+ consecutive rounds produce no rendering breakage or exception overflow is the Prompt qualified for pipeline commit.
