# 07.1. AI ギャルゲーエンジンの LLM API の進化と商業化・収益化戦略

> **種類**: アーキテクチャの進化と商業計画  
> **重点**: 長文テキストによるインタラクティブな謎解きやギャルゲー (Galgame) のシナリオに焦点を当て、大規模言語モデル (LLM) API の選定、メモリ (記憶) ボトルネックの突破、および製品化への道筋を探求します。

---

## コアの技術的課題：ステートレスプロトコルとトークンの爆発

インタラクティブなビジュアルノベルや AI 駆動の対話型ゲームを構築する際、開発者は次のような根本的な課題に直面します：

1. **公式の有料 API (Official APIs)**:
   - **特性**: RESTful に基づくステートレス (Stateless / 状態を持たない) プロトコル。
   - **課題**: NPC の行動がこれまでのあらすじと確実を一致するように、リクエストを送信するたびに完全な履歴や世界観の設定ファイル (Lore) を含めなければなりません。ゲームのプレイ時間が進むにつれて、入力トークン (Input Tokens) が指数関数的に膨れ上がり、推論コストの制御不能と深刻なネットワーク遅延を引き起こします。
2. **Web リバースエンジニアリング API (Web Reverse-engineered API)**:
   - **特性**: Web 版のネイティブな Session アーキテクチャを利用して、ステートフル (Stateful / 状態を持つ) な記憶を維持します。
   - **メリット**: トークンの課金制限を突破し、膨大なコンテキストウィンドウをサポートできます。
   - **リスク**: 極めて不安定であり、プラットフォームによるリスクコントロールによる遮断 (HTTP 403 Forbidden) に遭いやすく、長期的なメンテナンスコストが非常に高くなります。

---

## ゲームエンジン・アーキテクチャの進化ロードマップ (Architecture Roadmap)

「運用コスト」、「プレイヤー体験」、「システムの防御力」の間で最適なバランスを取るため、Moyin ゲームエンジンの LLM 連携戦略は以下の 3 つの段階に分けられます：

### v0：ステートマシンとローリングサマリー (State Machine & Rolling Summary)

- **運用メカニズム**: ゲームエンジンが記憶の管理に積極的に介入します。構造化された状態設定 (`state.json`) と圧縮された「動的なローリングサマリー (`summary`)」を維持し、直近 N=8 ターンの会話履歴 (`recent_dialogue`) のみを LLM に送信します。
- **アーキテクチャのメリット**: Input Tokens を定数レベルの範囲に正確に制御し、プレイ時間に比例してコストが線形に増大する問題を徹底的に根絶します。
- **出力の仕様**: LLM に対して、厳格な JSON フォーマットを返すように強制します (この中には、`narrative` の地の文、`choices` の分岐、および `state_delta` の状態変更が含まれていなければなりません)。

### v1：コントローラー層とライター層の分離 (Controller-Writer Pattern)

- **運用メカニズム**: デュアルモデル協調ルーティングを導入します。軽量の推論モデル (Controller) をフロントに配置し、バックエンドには深い感情移入能力を持つトップクラスのモデル (Writer、Gemini Pro や Claude 3.5 など) を隠しておきます。
- **職責の分割**: Controller はプレイヤーの入力意図を判定することに専念し、必要に応じて部分的な世界観 (Lore) ブロックを動的に抽出して注入し、無意味な対話をフィルタリングします。そして最終的に、ストーリーを執筆するために高価な Writer モデルをトリガーするかどうかを決定します。
- **アーキテクチャのメリット**: 漏斗 (ファネル) 式の迎撃により、トップクラスの推論モデルの呼び出し頻度と必要なコンテキストの負荷を最大限に削減します。

### v2：全体的なローカル推論 (Fully Localized Deployment)

- **運用メカニズム**: プレイヤーのローカルマシン上に、7B〜8B クラスのオープンソースの中国語物語推論モデル (Llama-3-8B-Instruct, Qwen-2.5 など) を展開し、`llama.cpp` (GGUF Q4_K_M 量子化フォーマット) を通じて高性能なローカル推論を実行します。
- **システムのやり取り**: ゲームのクライアントには軽量な Local LLM Server が組み込まれており、外部に対して OpenAI 互換の接続インターフェースを提供し、100% ネットワークから切断されたオフラインプレイを実現します。
- **アーキテクチャのメリット**:
  - **API コスト 0 (ゼロ)**: クラウドのトークンサブスクリプション課金制度から完全に脱却します。
  - **究極のプライバシー保護**: プレイヤーの会話データは決して国境を越えず、コンプライアンス審査のリスクを排除します。
  - **超低遅延**: プレイヤーのコンシューマー向けグラフィックボード (RTX 30/40 シリーズなど) を活用することで、ミリ秒レベルのストリーミング生成体験を実現します。
- **実務上の制限と解決策**: ローカルモデルはハードウェアによって制限されるため、コンテキストウィンドウはより保守的でなければならず (N=6、サマリーは 200〜500 トークンに制限)、厳密な状態遷移を行うために、エンジン側の `state_delta` JSON に一層強く依存することになります。

---

## 商業化・収益化と運営戦略 (Commercialization Strategy)

### フェーズ 1：MVP 実用最小限の製品 (Market Validation)

- 「無自覚のハイジャック/注入 (Cookie Capture)」などの認証技術を導入し、プレイヤー自身の無料ユーザー向け Web サービスを紐づけることを許可します。これにより、ゲームのクラウドサーバー運営コストを大幅に引き下げ、迅速に市場の反応を測り、コミュニティのトラフィックを拡大します。

### フェーズ 2：BYOK - Bring Your Own Key 方式

- 「スタンドアローン版ランチャーとエンジンコアの販売」を中心としたビジネスモデルへと転換します。プレイヤーは設定画面で、個人的に申請したクラウド API キー (Gemini / Claude など) を紐づける必要があります。
- **主要なセールスポイント (USP)**: 消費者が実質的に購入するのは、Moyin 開発チームが丹念に練り上げた **Prompt (プロンプト) フレームワーク**、**閉鎖式メモリ管理アルゴリズム**、および **独占的なシナリオモジュール** であり、基礎となる言語能力そのものではありません。

### フェーズ 3：コンプライアンスとプライバシー免責事項 (Compliance & Disclaimer)

- ソフトウェアのエンドユーザー使用許諾契約 (EULA) の中に、明確に記載しなければなりません：本サービスの中枢神経は外部のクラウド推論に依存していますが、すべての過去の会話トークン配列はプレイヤーのローカルコンピュータにのみ保存され、バックグラウンドでのアップロードやサーバーへのバックアップは決して行われません。
- 万が一サーバー側で不可抗力による接続異常が発生した場合、開発者はクライアント側のブリッジを修復する責任のみを負い、サードパーティのモデル提供者による制限については免責されるものとします。

---

## 💡 Vibecoding 指令

AI エージェントにギャルゲーエンジンやシステム向けの LLM パイプラインの中核アーキテクチャを実装させる際：

> 🗣️ `「ギャルゲーエンジンの AI コアを構築する際、【ステートマシンとローリングサマリー (State Machine & Rolling Summary)】パターンを厳格に実装してください。トークンコストの爆発を防ぐため、生の状態の会話履歴全体を LLM API に渡すことは絶対にやめてください！ 代わりに、簡潔な 'state.json' と直近の会話のローリングサマリーを維持してください。また、安価な意図ルーティングと高価なクリエイティブ生成を分離するための【Controller-Writer パターン】を確立してください！」`
