# 07.3. ComfyUI 画像・音声生成モデル調達ガイド

> **種類**: AI モデルの選定およびオープンソース・コンポーネント解析
> **重点**: ComfyUI というノードベースのワークフローエンジンに焦点を当て、チェックポイント (Checkpoint)、LoRA、ControlNet、およびマルチモーダル拡張パッケージ間の違いと位置づけを体系的に整理します。

---

ComfyUI エコシステムを高度に自動化された映像・音声ポストプロダクションスタジオと捉えると、`.safetensors` などの特殊な拡張子を持つ各種モデル重みファイルは、スタジオ内で雇われた異なる専門分野のマスターに相当します。ここでは Moyin プロジェクトのために、各モジュールの専門領域と物理的なストレージ規約を整理します。

---

## 1. コア画像推論エンジン (Base Generation Models)

通称「大型モデル」または「ベースモデル」と呼ばれ、テキストプロンプトに基づいて画面を構築する中核的な機能要素です。

| モデル階層 / アーキテクチャ | 技術特性と利点 | 推奨適用領域 |
| :--- | :--- | :--- |
| **SDXL (コストパフォーマンス (Cost-Performance) バランス型)** | 主流の拡散モデル (Diffusion Model) アーキテクチャです。優れたオープンソースコミュニティエコシステムを持ち、コンシューマーグレード GPU の VRAM 要件も適度です。 | バーチャルキャラクターのレンダリング、アニメ風イラスト。`Animagine XL 4.0` または二次元特化の `NoobAI XL` を強く推奨します。 |
| **Flux (最高峰のビジュアルクオリティ)** | 次世代アーキテクチャです。フォトリアリスティックな光と影を実現でき、さらに「画像内テキストの正確なスペリング」という型破りな進化を遂げています。ただし、計算メモリ消費量は極めて膨大です。 | `Flux.1 Dev`：商用グレードの写実素材やタイポグラフィが必要な画像に適しています。 |

> **ディレクトリ配置ガイドライン**: 上記の `.safetensors` 重みファイルと構造ファイルは、すべて `ComfyUI/models/checkpoints/` ディレクトリに配置してください。

---

## 2. 動的時系列・動画生成モデル (Video Generation Models)

静止画に物理的な流体ダイナミクス (Fluid Dynamics) や生命力を与えるモデルです。現在 Moyin ワークフローエコシステムでは、Alibaba (アリババ) がオープンソースで公開した高性能動画アーキテクチャ：**WAN 2.2 シリーズ**に強く依存しています。

| タスクカテゴリ | 動作原理 |
| :--- | :--- |
| **WAN 2.2 I2V** | Image-to-Video。単一または複数の静止画をシード (Seed) として、後続フレームのダイナミックビデオを推論・レンダリングします。 |
| **WAN 2.2 T2V** | Text-to-Video。純粋にテキストプロンプトを入力とし、拡散モデル (Diffusion Model) を通じて時空間次元で直接映像シーケンスを生成します。 |

> **ハードウェア負荷軽減対策 (量子化 / Quantization)**：
> 動画生成モデルの物理ファイルは通常極めて大きい (15GB 以上) です。GPU の VRAM オーバーロードやシステムクラッシュに遭遇した場合は、コミュニティリリースで **`FP8` (8ビット浮動小数点)** または **`GGUF`** のラベルが付いた低精度量子化圧縮版を優先的にダウンロードしてください。

---

## 3. ドメイン特化ファインチューニング拡張 (LoRA - Low-Rank Adaptation)

**Low-Rank Adaptation (LoRA)** は超軽量なモデルトレーニング手法です。メインモデルの巨大なニューラルネットワーク重みを凍結 (Freeze) し、極少数のサンプル (例：特定人物やアートスタイルの画像 20 枚) のみを用いてサイドブランチの計算レイヤーに挿入し、パラメータの特殊訓練を行います。

- **価値**：生成されるファイルは極めて小さく (約 100MB 程度)、自由にロード・ホットスワップ (Hot Swap) できます。AI が画像生成時に、指定されたマイナーキャラクターの顔の特徴を正確にロックして「模倣」したり、特定の水彩画/サイバーパンク (Cyberpunk) アートスタイルを適用したりするために使用されます。
- **ディレクトリ配置ガイドライン**: `ComfyUI/models/loras/` ディレクトリに配置してください。

---

## 4. ゼロショット音声クローニングエンジン (Zero-Shot TTS)

テキスト音声変換 (Text to Speech) モジュールは、バーチャルシステムにダイナミックに生成される音声を提供します。Moyin は以下の最高峰オープンソースソリューションを採用しています：

### GPT-SoVITS

現時点でのクロスリンガル音声合成の絶対的王者です。

- **コア技術**：ゼロショット推論 (Zero-Shot Inference)。ターゲットの録音ファイル 3〜5 秒分をリファレンスオーディオ (Reference Audio) として提供するだけで、システムがその場で声紋共鳴 (Voiceprint Resonance) を解析できます。
- **利点**：中国語、英語、日本語、韓国語、広東語など複数の言語バリアを完璧に互換ミキシングできます。ComfyUI Manager 内からシームレスにグラブ・マウントも可能です。

### IndexTTS2 (Bilibili コミュニティチームによる開発)

- **技術的焦点**：デプロイの難度はやや高いものの、「動画オーディオトラック長の絶対制御（後工程のリップシンク (Lip-Sync) アラインメントに有利）」および「高複雑度の感情解析（精密なトーンタグの配置をサポート）」において卓越したパフォーマンスを発揮します。

---

## 5. 画面精度の絶対制御と補助ノード (ControlNet & Consistency)

大規模言語モデルの最大の制御不能性は、画像のランダムドリフトにあります。以下の補助ニューラルネットワーク (ControlNets) は、強力な空間的またはスタイル的拘束器として機能します：

| 補助モデルタイプ | エンジニアリング目的と技術的効果 |
| :--- | :--- |
| **ControlNet (OpenPose)** | 姿勢スケルトンアンカー (Skeleton Anchor)。特製のスケルトンポイント図やスティックフィギュアスケッチを入力し、バックエンドの拡散モデル (Diffusion Model) の構図フレームワークを強制的に制約し、異常な肢体の増殖を防止します。 |
| **IP-Adapter** | 高密度スタイル転送器 (Style Transfer)。参照画像のビジュアル特徴、色調、または独自のブラシストロークを強力に抽出し、同等の美的テクスチャを新しく生成されるコンテンツに適用できます。 |
| **RIFE (フレーム補間ネットワーク / Frame Interpolation Network)** | AI フレームレンダラー。元の動画モデルの出力フレームレート (FPS) が低すぎて視覚的なスタッターが発生する場合、アルゴリズムを使用して 2 フレーム間の欠落した遷移フレームを計算し、60 FPS レベルにスムーズにアップスケーリングします。 |

---

_上記の基盤技術の分類に精通することで、ComfyUI のノードワークフローを構成する際に、必要なモデルコンポーネントを自信を持って選別し、高効率なコンテンツ制作ファクトリーを構築できるようになります。_
