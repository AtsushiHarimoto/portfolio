# 07.5. Ollama ローカルモデルデプロイメントとクラウド LLM 認証統合ガイド

> **種類**: 技術統合マニュアルとシステム操作ガイド
> **日付**: 2026-01-12 (改訂版 v1.2)
> **適用範囲**: Moyin ルーティングゲートウェイ (`web2api`) およびフロントエンド接続モジュール

---

## 概要

本ガイドは、Moyin プロジェクトにおける 2 つの主要な言語モデル統合戦略の標準作業手順を確立することを目的としています：

1. **ローカルホスティング (Local Hosting)**：Ollama サーバーのデプロイメント、異なる VRAM 階層に応じた高度なモデル選定、およびステートレスのボトルネックを突破するネイティブコンテキスト (Native Context) 継続対話技術をカバーします。
2. **クラウド API アクセス認証 (Cloud Authentication)**：Firefox アドオンワークフローを介して Cookie を無痛でハイジャック (Hijack) する実務的なアプローチを提示し、Gemini などのクラウドサービスのアンチボット (Anti-bot) およびトークン失効の課題を完全に解決します。

---

## 1. オフラインモデルハブ：Ollama デプロイメントガイド

### 1.1 起動とシステム常駐管理

- **環境インストール**: Windows 環境では、システムレベルのパッケージマネージャーで `winget install Ollama.Ollama` を実行するか、[Ollama 公式サイト](https://ollama.com) から直接ダウンロードすることを強く推奨します。
- **デーモンプロセスの起動**:
  - Windows ではデフォルトで起動時にバックグラウンドサービス (Windows Service) として常駐します。
  - 手動起動やリアルタイムログの確認が必要な場合は、ターミナルで `ollama serve` を実行してください。
- **ヘルスチェック (Health Check)**: ブラウザでローカルエンドポイント `http://localhost:11434/api/tags` に GET リクエストを送信し、標準の JSON モデルリストが返れば、サーバーのハートビートは正常です。
- **バッチ初期化**: 開発環境の一貫性を確保するため、新規メンバーは `.\projects\moyin-gateway\web2api\scripts\setup-ollama-models.ps1` を直接実行できます。システムが自動的にすべての依存モデルをポーリング・プルします。

### 1.2 VRAM に基づくエッジモデル選定戦略

インタラクティブなレスポンスの流暢さを確保するため、ホストマシンの物理 VRAM 構成に応じて以下の量子化モデルを厳格に適用してください：

| GPU メモリ閾値 | 推奨モデル層 | 実務シナリオとパフォーマンス特性 |
| :--- | :--- | :--- |
| **極限軽量 (2-4GB)** | `llama3.2:3b`, `phi3:mini` | 超高速推論。基本的な API カプセル化テストや低知能 NPC スケジューリングタスクに限定。 |
| **標準 (6-8GB)** | `qwen2.5:7b-instruct-q4_K_M` | **強く推奨**。繁体字中国語の語感とロジックのバランスが極めて優秀。ノート PC 開発機やギャルゲースタンドアロンエンジンの第一候補。 |
| **中上位 (12GB)** | `qwen2.5:14b-instruct` | 推論パスの深化。複数の状態変更 (State-Delta) を伴う複雑なシナリオ解析に専念。 |
| **フルパワー (24GB+)** | `qwen2.5:32b`, `qwq:32b-preview` | **RTX 3090/4090 専用**。エピックレベルの長文記憶と深層推論 (Deep Reasoning) 能力。 |

---

## 2. Web2API 通信アーキテクチャとパフォーマンス最適化

### 2.1 互換レイヤーを廃棄し、ネイティブコンテキストプロトコルを採用

ビジュアルノベルレベルの「ミリ秒レスポンス」を追求するため、アーキテクチャ上、従来の OpenAI 互換レイヤーを意図的に廃棄し、**Ollama ネイティブ API (`/api/chat`)** を深く統合しました：

- **KV Cache 再利用メカニズム**: Ollama は単一の推論完了後、`context` と呼ばれる整数型 TOKEN ID 配列（メモリスナップショット）を返します。
- **コンテキストピニング (Context Pinning)**: バックエンドのメモリライフサイクルマネージャー (`cache_manager`) を通じて、この `context` 配列をユーザーの `conversation_id` にハードバインドします。
- **蒸留パケット送信**: 後続の会話では、クライアント（Web フロントエンド）は最新の指示と履歴 `context` スライスのみを送信するだけで済み、冗長な履歴テキストの再トークナイズ (Tokenize) プロセスを排除します。計算負荷はほぼゼロに低下します。

### 2.2 持続的ペルソナとスクリプトモードのクランプ

- **アンチハルシネーション (Anti-Hallucination) の強い制約**: オープンソース推論モデルは予期しない思考の断片（例：`<thought>` タグ）を生成しがちです。強力なシステムプロンプト (System Prompt) を展開してこれを強制的に抑制し、`JSON.parse` で処理可能な純粋な文字列のみを出力するよう制約する必要があります。
- **ワールドビューアンカリング (World-View Anchoring)**: 主人公の性格とワールドビューを `SYSTEM_INSTRUCTION_JSON` として定数化し、`context` がロードされるたびに強制的にアンカリングして、長時間の対話後のペルソナの弱体化とドリフトを防止します。

---

## 3. クラウドリバースエンジニアリング API の Cookie 認証ハイジャック

### 3.1 セッションの有効期限と暗号化のジレンマ

プロジェクトがクラウドの無料コンピューティング（Gemini や Grok の Web インターフェースへのリバースアクセス）に切り替える場合、`__Secure-1PSID` や `sso_token` などのセッション Cookie に依存する必要があります。ただし、これらの認証トークンには以下の致命的な欠点があります：

- **有効期間の短さ**: モデルプロバイダーが予告なくトークンをローテーションし、認証失敗を引き起こすことが頻繁にあります。
- **OS レベルの深層暗号化**: Chromium (v80+) の暗号化アルゴリズムは OS の基盤層 (例：Windows CryptUnprotectData) と深く絡み合っており、Python バックエンドでの直接復号が極めて困難で、アンチウイルスアラートを引き起こしやすいです。

### 3.2 突破口：Firefox サンドボックスブリッジ方式

実測の結果、**Mozilla Firefox** をアクセスブリッジとして使用することで、最も安定した自動化体験が得られることが確認されました：

1. **パス登録**: 初回設定時に、Firefox の実行ファイルの絶対パスを隠しファイル `.firefox_path` に登録します。
2. **記憶喪失の自動修復**: 仲介サーバー `run_game_api.ps1` 起動時に、システムが Cookie の有効期限チェックを自動的に開始します。
   - 期限切れまたは消去された場合、API はサーバーの起動を一時停止し、Firefox を起動して Gemini ログインインターフェースを表示します。
   - 開発者がブラウザを通じて認証情報を入力するまで、スクリプトの続行は保留されます。
3. **ロスレス抽出 (Lossless Extraction)**: `cookie_check.py` スクリプトが SQLite ドライバーを介して Firefox が確立した `cookies.sqlite` ファイルを直接クエリします。Firefox のローカルストレージポリシーは比較的緩やかで OS レベルのキーローテーションを強制しないため、抽出成功率はほぼ 100% に達します。

### 3.3 トラブルシューティングチェックリスト

- **トークンをインターセプトできない場合**: Firefox のプライバシー設定を確認し、「Firefox を閉じたときに Cookie とサイトデータを削除する」オプションが**無効**になっていることを確認してください。
- **パス解決エラー**: Firefox のアップグレードによりパスがずれた場合は、`.firefox_path` ファイルを削除してください。ゲートウェイスクリプトを再起動すると、再ナビゲーション登録プロセスがトリガーされます。
