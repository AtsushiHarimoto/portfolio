# 39. 冰與火之歌：高低溫資料分層儲存 (Data Tiering)

> **類型**: 大數據儲存架構與資料庫成本控制
> **重點**: 資料就像鮮奶，有保鮮期。如果把十年前沒人看的報表跟當下每秒十萬筆的訂單混在同一個高薪聘請的「記憶體叢集」裡，公司一定會破產。本章探討如何建立**自動漸凍層 (Hot/Warm/Cold Storage Tiering)**，在極致效能與極致摳門中取得完美平衡。

---

## 前言：SSD 不能買來當倉庫用

很多初創公司在剛拿到融資時，為了追求「快」，把所有的資料統統塞進 AWS 最昂貴的 EBS 固態硬碟 (SSD)，甚至大舉建立 Redis 記憶體叢集。
一年後，這家公司的 AWS 帳單從每個月五百塊美金，飆升到每個月兩十萬美金。

**因為他們犯了最致命的錯誤：沒有進行資料溫度分層 (Data Temperature Tiering)**。
在一個有五年歷史的電商網站，95% 的使用者只會查詢「最近 30 天」的訂單。你花高昂代價把「三年前雙 11 的失敗訂單紀錄」存放在毫秒級存取的 SSD 裡，那不叫技術，那叫敗家。

---

## 1. 溫度的定義：Hot, Warm, Cold

架構師必須化身為精算師，將流入系統的資料進行無情的分級：

### 🔥 熱資料 (Hot Data)

- **定義**：現在、立刻、馬上需要被頻繁讀寫的資料。
- **範例**：今天的最新新聞、使用者購物車裡的商品、目前的股票即時報價。
- **武器庫**：放在最昂貴的地方。Redis (記憶體)、高階 SSD、NVMe。存取時間要求在幾毫秒到數十毫秒之間。這層的容量通常最小 (佔總資料的 5%)，但燒掉 50% 的預算。

### 🌤️ 溫資料 (Warm Data)

- **定義**：偶爾會被翻一下，雖然不用一毫秒就跳出來，但也不能讓使用者等超過三秒。
- **範例**：上個月的電子發票、半年前的對話紀錄。
- **武器庫**：傳統機械硬碟 (HDD)、一般版本的關聯式資料庫 (如 MySQL)、Elasticsearch 叢集。存取時間在數百毫秒內。

### ❄️ 冷資料 (Cold Data) 與 冰凍資料 (Archive)

- **定義**：幾乎沒有人會看，但因為【法律審計規定】（例如金管會要求交易紀錄保留七年）而被迫不能刪除的超級歷史檔案。
- **範例**：2016 年的 Server Access Logs、五年以上的退貨明細。
- **武器庫**：便宜到令人髮指的廉價儲存庫。例如 AWS S3 Standard-IA (不常存取層)，甚至是終極的 **Amazon S3 Glacier (極冰層)**。
  _(註：Glacier 的儲存費趨近於免費，但代價是：如果你老闆某天發瘋要調閱五年前的報表，你發送 API 請求後，**可能必須等 12 個小時**，資料才會從深層磁帶中被挖出來「解凍」給你！這是一種極端的時間換取金錢魔法。)_

---

## 2. 奇蹟降臨：自動生命週期管理 (Lifecycle Hooks)

你絕對不可能請一個工程師，每天半夜手動把 MySQL 的舊資料 Dump 出來丟去便宜的 S3。這必須全自動化。

### 🔄 漸凍人的轉移矩陣

在現代雲端架構 (如 AWS S3) 中，只要點擊幾個設定，就能開啟名為 **Lifecycle Configuration (生命週期規則)** 的流沙陷阱：

1. 使用者剛上傳一支影片，這 30 天內剛好爆紅，所有人都在看，這支影片停留在最貴的 S3 Standard 層。
2. 30 天後，熱度下降，系統「自動」把影片打入 **S3 IA (不常存取層)**，儲存費瞬間砍半。
3. 滿 1 年後，再也沒人看這支影片了，系統無情地將它打包，丟進 **S3 Glacier Deep Archive (極冰層)**，儲存費降為原來的千分之一。
4. 萬一三年後這支影片突然又被翻出來爆紅？系統會收你一筆「解凍費」，但這三年來你省下的錢早已是天文數字。

---

## 3. 資料庫的冷熱分離 (Database Tiering)

不只是檔案系統，關聯式資料庫（如 MySQL / PostgreSQL）也需要冷熱分離。
如果一張 `orders` 表裡面累積了五億筆十年來的訂單，每次你下一個 `INSERT`，B-Tree 索引重排的重量會把資料庫拖垮。

**解法：歷史表切割 (Historical Archiving / Partitioning)**：
架構師必須寫一支排程腳本 (CronJob 或是使用 Kafka Connector)：

- 找出 `created_at < 2023-01-01` 的所有超過兩年的訂單。
- 把這些舊訂單轉移到另一張名為 `orders_history_2022` 的表（或是乾脆移轉到大數據專用的便宜資料倉儲如 Hive / Redshift）。
- 在目前的高能資料庫中，把這些舊資料 `DELETE` 刪除（別忘了做索引重建）。
  這使得第一線迎戰百萬流量的 `orders` 表，永遠保持輕盈與極致的神速。

---

## 💡 Vibecoding 工地監工發包訣竅

在使用 AI Agent 建構含有使用者足跡日誌、巨型相簿、或是歷史交易紀錄的系統時：

> 🗣️ `「你在幫我使用 AWS CDK 或 Terraform 規劃這座巨型影片儲存 S3 Bucket 時，嚴禁只給我開一個預設的 Standard 層就交差！請你立刻加上【Lifecycle Rule (生命週期規則)】的代碼配置。我要你設定：檔案滿 30 天且超過 1MB 者，自動降級轉移至 【Infrequent Access (IA)】 層；滿 365 天未見天日之陳年檔案，請無情地打入 【Glacier Deep Archive】 進行深度冷藏。這關乎我們每季上千美金的基礎設施帳單，不可兒戲！」`
